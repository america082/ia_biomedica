{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24b5921a-31c4-45a0-b1f0-e60e7b53b5f7",
   "metadata": {},
   "source": [
    "#Práctica 3: CNN.\n",
    "##Introducción\n",
    "Una CNN (Convolutional Neural Network, o Red Neuronal Convolucional) es un tipo de arquitectura de red neuronal usualmente utilizada en tareas relacionadas con el análisis de datos espaciales o estructurados, como imágenes y videos. Las CNNs están diseñadas para aprovechar las estructuras locales de los datos y son especialmente efectivas en la detección de patrones como bordes, texturas, y formas en imágenes. Por su parte, el dataset seleccionado para la realización de esta práctica consiste en un gran numero de imágenes segmentadas de núcleos biológicos pertenecientes a células de una amplia variedad de contextos.\n",
    "##Objetivo\n",
    "####En esta práctica se implementará una red neuronal de tipo CNN para el análisis de un dataset que contiene datos de núcleos biológicos.\n",
    "#Metodología"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50826812-9d25-460a-a670-a5d36704df80",
   "metadata": {},
   "source": [
    "###Carga de librerías.\n",
    "####En esta primera parte del código se importaron las librerías necesarias para el desarrollo del código. La librería \"os\" para manejo del sistema operativo, \"numpy\" para operaciones numéricas, \"tensorflow\" para construir y entrenar la red neuronal, y \"matplotlib\" para graficar resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "164d5e0b-b35d-4e94-9189-2cdba40380d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Matplotlib requires numpy>=1.20; you have 1.19.2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers, models\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ai_biomedica/lib/python3.8/site-packages/matplotlib/__init__.py:227\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m parse_version(module\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m parse_version(minver):\n\u001b[1;32m    223\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatplotlib requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m                               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 227\u001b[0m \u001b[43m_check_versions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;66;03m# The decorator ensures this always returns the same handler (and it is only\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# attached once).\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mlru_cache()\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ensure_handler\u001b[39m():\n",
      "File \u001b[0;32m~/miniconda3/envs/ai_biomedica/lib/python3.8/site-packages/matplotlib/__init__.py:223\u001b[0m, in \u001b[0;36m_check_versions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    221\u001b[0m module \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(modname)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parse_version(module\u001b[38;5;241m.\u001b[39m__version__) \u001b[38;5;241m<\u001b[39m parse_version(minver):\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMatplotlib requires \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m>=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminver\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    224\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou have \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: Matplotlib requires numpy>=1.20; you have 1.19.2"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5391af8-7687-467b-9102-ddfcfedacb11",
   "metadata": {},
   "source": [
    "###Definición de rutas y parámetros\n",
    "####Aquí se definen las rutas a los directorios de entrenamiento y validación. Además, se establecen las dimensiones de las imágenes (IMG_HEIGHT y IMG_WIDTH) y el tamaño del lote (BATCH_SIZE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0511758b-4ee4-4ecc-9a15-b8ef74b16a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las rutas a los directorios de entrenamiento y validación\n",
    "train_dir = '/mnt/c/Users/Usuario/Desktop/entorno/l'\n",
    "validation_dir = '/mnt/c/Users/Usuario/Desktop/entorno/s'\n",
    "\n",
    "# Definir el tamaño de las imágenes y el tamaño del lote\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 128\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854d78d0-ddb2-484f-bf94-828f5210663f",
   "metadata": {},
   "source": [
    "###Generadores de datos\n",
    "####Se crearon los generadores de datos para cargar y preprocesar las imágenes, escalando los valores de los píxeles a un rango de 0 a 1. flow_from_directory carga imágenes de los directorios especificados y ajusta su tamaño."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3400fc3c-6883-421d-ad4d-6fd0130df51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear generadores de datos para cargar y preprocesar las imágenes\n",
    "train_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data_gen = train_image_generator.flow_from_directory(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    directory=train_dir,\n",
    "    shuffle=True,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "val_data_gen = validation_image_generator.flow_from_directory(\n",
    "    batch_size=BATCH_SIZE,\n",
    "    directory=validation_dir,\n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e7ea5e-4cf3-4193-9d99-99147308bbe3",
   "metadata": {},
   "source": [
    "###Definición de la arquitectura de la CNN\n",
    "####°Capas convolucionales (Conv2D): Detectan características en las imágenes usando filtros.\n",
    "####°Capas de agrupamiento (MaxPooling2D): Reducen la dimensionalidad.\n",
    "####°Aplanado (Flatten): Convierte la matriz 2D resultante de las capas convolucionales en un vector 1D.\n",
    "####°Capas densas (Dense): Realizan la clasificación final. La última capa utiliza la función de activación sigmoid para salida binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848b5563-9bf3-4fb4-adc6-33d5b1012fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la arquitectura de la CNN\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9f56dc-c513-42db-83bf-c16777c7d814",
   "metadata": {},
   "source": [
    "###Compilación y resumen del modelo.\n",
    "####Compila el modelo especificando el optimizador (adam), la función de pérdida (binary_crossentropy), y las métricas (accuracy). Luego se muestra un resumen del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d56bc07-2e3a-45a2-ba13-559ced3f7fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Resumen del modelo\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5db914-29b2-4654-9c8e-49f4b8184320",
   "metadata": {},
   "source": [
    "###Entrenamiento del modelo.\n",
    "####Se entrena el modelo utilizando los generadores de datos de entrenamiento y validación. steps_per_epoch y validation_steps especifican el número de pasos por época. epochs define el número de épocas de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7f8821-c21a-425f-844b-7ec7e689ebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el modelo\n",
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=train_data_gen.samples // BATCH_SIZE,\n",
    "    epochs=15,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=val_data_gen.samples // BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b6de38-5ff1-4a0e-99cc-4881caaae83a",
   "metadata": {},
   "source": [
    "###Evaluación del modelo.\n",
    "####Se evalúa el rendimiento del modelo en los datos de validación y se imprime la pérdida (loss) y la precisión (accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715de1eb-b3e6-40a5-ae4a-565bc2238ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo\n",
    "loss, accuracy = model.evaluate(val_data_gen)\n",
    "print(f'Loss: {loss}, Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb699f8-e14d-414e-9940-bfb9b571836e",
   "metadata": {},
   "source": [
    "###Graficación de los resultados.\n",
    "####Extaccion de los datos del historial y definición del rango de épocas.\n",
    "#####El objeto history contiene el historial de entrenamiento del modelo. history.history es un diccionario que almacena las listas de valores de precisión (accuracy), precisión de validación (val_accuracy), pérdida (loss) y pérdida de validación (val_loss) para cada época del entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c0ac01-0cdb-4d59-9492-bebf46ef44cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar la precisión y la pérdida durante el entrenamiento\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d28cd40-ebaf-424a-9442-6132ba61cd03",
   "metadata": {},
   "source": [
    "###Creación de los gráficos.\n",
    "####Se hacen las gráficas de precisión y pérdida. La gráfica de Precisión (Accuracy) permite ver cómo la precisión del modelo en los datos de entrenamiento y validación cambia a lo largo de las épocas. Por su parte, la gráfica de Pérdida (Loss) muestra cómo la función de pérdida del modelo se comporta durante el entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c8b1de-9118-45cf-bca2-2629b480f8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
