{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso práctico 3 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la primera parte, el programa busca que tengas los archivos y estos se descarguen para poder trabajar con ellos, se edita su primera variable, ya que mis archivos son locales y no descargadas de la web, se usan diveras funciones en fin de que tengamos nuestra base de datos lista para manipularse.\n",
    "Primero se combinan mis archivos locales y se reparan, para posteriormente eliminar los archivos zip orginales combinados, louego comenzamos a descompromimir el archivo que ya habíamos reparado.\n",
    "En las últimas 2 líneas, se cuentan los archivos descomprimidos y se instala el hdf5storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat \"C:/Users/DELL/Downloads/stage1_train.zip\" \"C:/Users/DELL/Downloads/stage1_test.zip\" \"C:/Users/DELL/Downloads/stage2_test_final.zip\" > combined_temp.zip\n",
    "!zip -FF combined_temp.zip --out data.zip\n",
    "!rm \"C:/Users/DELL/Downloads/stage1_train.zip\" \"C:/Users/DELL/Downloads/stage1_test.zip\" \"C:/Users/DELL/Downloads/stage2_test_final.zip\"\n",
    "!unzip data.zip -d data && rm data.zip\n",
    "!ls data | wc -l\n",
    "!pip install hdf5storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hacen las importaciones, de librerías hy funciones que nos ayudan con el procesamiento de datos y manejo de los argumentos a trabajar, creando igualmente una excepcion oara en caso de que no se enecuentre el archivo, creando una función def que solucione lo que courre enncaso de no poder localizar el archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "import hdf5storage\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "class NoDataFound(Exception):\n",
    "    pass\n",
    "\n",
    "def dir_path(path):\n",
    "    \"\"\"Check the path and the existence of a data directory\"\"\"\n",
    "    path = path.replace('\\\\', '/')\n",
    "    data_path = os.path.join(path, 'data').replace('\\\\', '/')\n",
    "    if os.path.isdir(data_path):\n",
    "        return path\n",
    "    elif os.path.isdir(path):\n",
    "        raise NoDataFound('Could not find a \"data\" folder inside directory. {} does not exist.'\n",
    "                          .format(data_path))\n",
    "    else:\n",
    "        raise NotADirectoryError(path)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creacion de imagenes, etiquetas y máscaras de matrices numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después se manda al directorio correcto en donde tengo mis archivos locales; para luego proseguir con el proceso de creación de imagenes, etiquetas y las matrices. \n",
    "En un principio, hice la creación de las nuevas clases, ya con nuestro porpio dataset adaptado, después hice un gráfico de barras capaz de mostrar la distribución.\n",
    "Para luego hacer una visualización de las primeras tres imágenes junto con sus máscaras y las máscaras superpuestas en las imágenes originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integer_to_class = {'1': 'Humano', '2': 'Ratón', '3': 'Mosca'}\n",
    "\n",
    "labels = np.load('labels.npy')\n",
    "images = np.load('images.npy')\n",
    "masks = np.load('masks.npy')\n",
    "\n",
    "classes, counts = np.unique(labels, return_counts=True)\n",
    "plt.bar(classes, counts, tick_label=[integer_to_class[str(cls)] for cls in classes])\n",
    "for i, idx in enumerate(classes):\n",
    "    print('number of {}: {}'.format(integer_to_class[str(idx)], counts[i]))\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "for i in range(3):\n",
    "    plt.subplot(3, 3, 1 + i * 3)\n",
    "    plt.title('Input')\n",
    "    plt.imshow(images[i, :])\n",
    "    plt.subplot(3, 3, 2 + i * 3)\n",
    "    plt.title('Mask')\n",
    "    plt.imshow(masks[i, :])\n",
    "    plt.subplot(3, 3, 3 + i * 3)\n",
    "    plt.title('Detection')\n",
    "    plt.imshow(images[i, :], cmap='gray')\n",
    "    mask = np.ma.masked_where(masks[i] == False, masks[i])\n",
    "    plt.imshow(mask, alpha=0.8, cmap='Set1')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de ello, se generaron 18 imágenes aleatorias para ver la diversidad y precisión del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "for i, idx in enumerate(np.random.randint(images.shape[0], size=18), start=1):\n",
    "    plt.subplot(3, 6, i)\n",
    "    plt.imshow(images[idx], cmap='gray')\n",
    "    mask = np.ma.masked_where(masks[idx] == False, masks[idx])\n",
    "    plt.imshow(mask, alpha=0.8, cmap='Set1')\n",
    "    plt.title(integer_to_class[str(labels[idx])])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delimitación y redimensionamiento de imagenes\n",
    "\n",
    "Uso de funciones y variables para acomodar y acoplar las imagenes ya obtenidas.\n",
    "La primera es una función get_bounding_box y la segunda es crop_to_bbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bounding_box(mask):\n",
    "    \"\"\"Return the bounding box of a mask image.\"\"\"\n",
    "    xmin, ymin, xmax, ymax = 0, 0, 0, 0\n",
    "    for row in range(mask.shape[0]):\n",
    "        if mask[row, :].max() != 0:\n",
    "            ymin = row\n",
    "            break\n",
    "    for row in range(mask.shape[0] - 1, -1, -1):\n",
    "        if mask[row, :].max() != 0:\n",
    "            ymax = row\n",
    "            break\n",
    "    for col in range(mask.shape[1]):\n",
    "        if mask[:, col].max() != 0:\n",
    "            xmin = col\n",
    "            break\n",
    "    for col in range(mask.shape[1] - 1, -1, -1):\n",
    "        if mask[:, col].max() != 0:\n",
    "            xmax = col\n",
    "            break\n",
    "    return xmin, ymin, xmax, ymax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_to_bbox(image, bbox, crop_margin=10):\n",
    "    \"\"\"Crop an image to the bounding by forcing a squared image as output.\"\"\"\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    max_width_height = np.maximum(y2 - y1, x2 - x1)\n",
    "    y2 = y1 + max_width_height\n",
    "    x2 = x1 + max_width_height\n",
    "    y1 = np.maximum(y1 - crop_margin, 0)\n",
    "    y2 = np.minimum(y2 + crop_margin, image.shape[0])\n",
    "    x1 = np.maximum(x1 - crop_margin, 0)\n",
    "    x2 = np.minimum(x2 + crop_margin, image.shape[1])\n",
    "    return image[y1:y2, x1:x2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de ello, se hace un proceso de recorte y delimitación de las imagenes, comenzando por recortarlas a su cuadro delimitador y redimensionarlas a un tamaño uniforme, para después visualizar el resultado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "\n",
    "dim_cropped_image = 224\n",
    "images_cropped = []\n",
    "for i in range(images.shape[0]):\n",
    "    if i % 10 == 0:\n",
    "        clear_output(wait=True)\n",
    "        display('[{}/{}] images processed: {:.1f} %'.format(i+1, images.shape[0], (i+1) / images.shape[0] * 100))\n",
    "    bbox = get_bounding_box(masks[i])\n",
    "    image = crop_to_bbox(images[i], bbox, 20)\n",
    "    image = cv2.resize(image, dsize=(dim_cropped_image, dim_cropped_image), interpolation=cv2.INTER_CUBIC)\n",
    "    images_cropped.append(image)\n",
    "\n",
    "clear_output(wait=True)\n",
    "display('[{}/{}] images processed: {:.1f} %'.format(i+1, images.shape[0], (i+1) / images.shape[0] * 100))\n",
    "\n",
    "images_cropped = np.array(images_cropped)\n",
    "print(images_cropped.shape)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "for i, idx in enumerate(np.random.randint(images_cropped.shape[0], size=18), start=1):\n",
    "    plt.subplot(3, 6, i)\n",
    "    plt.imshow(images_cropped[idx], cmap='gray')\n",
    "    plt.title(integer_to_class[str(labels[idx])])\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importaremos los modulos necesarios para trabajar con imagenes y cargaremos los datos, para después volver a redimensionar las diversas imagenes que ya obtuvimos anteriormente. \n",
    "Al final se recorre cada imagen en el dataset y se normaliza, es decir, se escalan los píxeles para que estén en el rango [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import sys\n",
    "import numpy as np\n",
    "import hdf5storage\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load('labels.npy')\n",
    "images = np.load('images.npy')\n",
    "masks = np.load('masks.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images[..., np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(images.shape[0]):\n",
    "    images[i, :, :] = (images[i, :, :] - np.min(images[i, :, :])) / (np.max(images[i, :, :]) - np.min(images[i, :, :]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas de evaluación \n",
    "dice_coef, dice_coef_loss, bce_dice_loss: Definen funciones de pérdida y métrica personalizada para el modelo U-Net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.losses import binary_crossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "smooth = 1\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1.-dice_coef(y_true, y_pred)\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) + dice_coef_loss(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### División de datos en entrenamiento, validación y prueba:\n",
    "\n",
    "Divide el conjunto de datos en tres partes: entrenamiento, validación y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train, images_test, masks_train, masks_test = train_test_split(images, masks, test_size=0.2, train_size=0.8, random_state=1)\n",
    "images_test, images_cv, masks_test, masks_cv = train_test_split(images_test, masks_test, test_size=0.5, train_size=0.5, random_state=1)\n",
    "\n",
    "print(\"number of training examples = \" + str(images_train.shape[0]))\n",
    "print(\"number of development examples = \" + str(images_cv.shape[0]))\n",
    "print(\"number of test examples = \" + str(images_test.shape[0]))\n",
    "print(\"Images_train shape: \" + str(images_train.shape))\n",
    "print(\"Masks_train shape: \" + str(masks_train.shape))\n",
    "print(\"Images_val (dev) shape: \" + str(images_cv.shape))\n",
    "print(\"Masks_val (dev) shape: \" + str(masks_cv.shape))\n",
    "print(\"Images_test shape: \" + str(images_test.shape))\n",
    "print(\"Masks_test shape: \" + str(masks_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición del modelo U-Net:\n",
    "Construcción del modelo U-Net para la segmentación de imágenes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet(input_size=(224, 224, 1)):\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
    "    conv1[_{{{CITATION{{{_1{](https://github.com/TannerFry/CS525-Final-Project/tree/972297369dc9af46c22ce2ad552e470c219fc038/extract_crops.py)[_{{{CITATION{{{_2{](https://github.com/haboub4500/Segmentation-of-biological-cells/tree/dce03362feb151ae7186bf592c5022322edbd2ac/model.py)[_{{{CITATION{{{_3{](https://github.com/johnmattox/TCC_Pait/tree/4f49b0a5c71ae2e33a73f0fa46bf283a780b1903/U-NET%2Ftrain_unet.py)[_{{{CITATION{{{_4{](https://github.com/DomSas/2D-unet/tree/390e23abd13d8e41e71a2f33693de24b5819bd7a/server_code_model_mar_2D.py)[_{{{CITATION{{{_5{](https://github.com/rciric/deep-generative-connectome/tree/aad6b95130306dd00ad23f493f21e33b93bf6aa4/connectogen%2Fmodels%2Fvae%2Fsubtle_metrics.py)[_{{{CITATION{{{_6{](https://github.com/EvergreenTree/mosinska2018beyond/tree/3612abde89f6de87ed3e16e933d4ed1d4092234d/unet_server.py)[_{{{CITATION{{{_7{](https://github.com/selamgit/segmentation_with_U-net/tree/075c0eb7045d21473b28e2f9af045d04a2dac4bd/model.py)[_{{{CITATION{{{_8{](https://github.com/jaybo/model_crack_detect/tree/d21e380706f33ca6007600292a4d009c5a6c61c5/models.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
